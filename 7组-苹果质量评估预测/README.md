# 大数据分析项目说明文档

## 1.项目结构

1. 数据可视化

2. 回归拟合模型

3. 分类算法

4. 聚类分析

## 2.项目说明

本项目的目的是建立分类模型，通过苹果的各项数据分辨出该苹果的质量，质量只有两个评级：好/坏

本项目使用的数据来自

[]([Apple Quality Analysis Dataset | Kaggle](https://www.kaggle.com/datasets/tejpal123/apple-quality-analysis-dataset))

该数据集统计了苹果的多个指标，包括

* Size: 大小
* Weight: 重量
* Sweetness: 甜度
* Crunchiness: 松脆度
* Juiciness: 多汁度
* Ripeness: 成熟度
* Acidity: 酸度
* Quality: 品质

数据已经经过了处理，可以直接进行数据分析操作

### 2.1概述

#### 2.1.1数据可视化

在数据可视化步骤中，绘制了我苹果质量好/坏占比的饼图，得到数据集中苹果的质量好坏成均匀分布，两者各占50%，样本偏差较小，对于训练模型显然是有好处的。

然后计算了Sperman相关系数矩阵，分析各元素之间的相关程度，并绘制了热力图，便于分析。

#### 2.1.2回归拟合模型

前文提到本项目的目标其实是构建一个二分类模型，所以其实不该用回归模型，不过既然写了就...

这里我使用了五种回归模型进行训练，使用10折交叉检验来判断模型的效果

```
models['LR'] = LinearRegression()
models['LASSO'] = Lasso()
models['EN'] = ElasticNet()
models['KNN'] = KNeighborsRegressor()
models['CART'] = DecisionTreeRegressor()
models['SVM'] = SVR()
```

虽然出发点是错的，但是得到了出乎意料的结果，KNN和SVR在某种程度上也能处理二分类问题，所以这两个模型在五个选项中是得分最高的，所以在之后的训练分类模型时也将KNN和SVC作为选项。

#### 2.1.3分类算法

我在这里使用了3种不同模型

1、KNN

2、SVC

3、随机森林，简写为RFC

训练的步骤大同小异，首先划分好训练集：train、测试集：test以及验证集：validation，比例为6：2：2

训练完模型后绘制对应的ROC曲线判断初步分类结果好坏。

然后使用随机网格参数搜索，在给定的模型参数范围内搜索出最佳的参数组合，然后用优化好的模型再次绘制ROC曲线观察优化效果（效果一般）

除了roc曲线，混淆矩阵也作为判断分类效果的依据之一。

最后在验证集上得出模型的准确率，精确率，召回率，F1分数四个指标

结果是SVC效果最好

#### 2.1.4聚类分析

尝试以苹果的大小，重量，甜度作为指标将苹果分为3类，作为定价的参考，（比如普通/高级/特级...）

不过得出的结果不太行，就当图一乐了：）

### 3 具体分析-chatgpt给出

#### 3.1数据可视化

这段代码的作用是对一个名为 "apple_quality.csv" 的数据进行分析和可视化。下面是代码的解读：

1. 首先，导入了必要的库：
   
   - `numpy`：用于处理数值数据。
   - `pandas`：用于数据处理和分析。
   - `matplotlib.pyplot`：用于绘制图表。
   - `matplotlib.font_manager` 和 `seaborn`：用于设置字体和绘制热力图。
   - `scipy.stats` 中的 `spearmanr`：用于计算斯皮尔曼相关系数。
   - `warnings`：用于忽略警告信息。

2. 定义了字体文件路径 `font_path`，并设置了中文字体为微软雅黑，确保图表中文字符显示正常。

3. 忽略了警告信息。

4. 使用 `pd.read_csv()` 读取名为 "apple_quality.csv" 的数据文件，存储到名为 `data` 的 DataFrame 中，并打印出数据集的列名和形状。

5. 将数据转换为 DataFrame 格式。

6. 开始绘制图表：
   
   - 绘制了一个饼图，展示了苹果好坏的占比。
   - 计算了好苹果和坏苹果的数量，计算了它们所占比例，并绘制了饼图。

7. 使用 `spearmanr()` 函数计算了数据中除第一列（假设是标签列）之外的每一列之间的斯皮尔曼相关系数矩阵和对应的 p 值矩阵。

8. 打印了斯皮尔曼相关系数矩阵和对应的 p 值矩阵。

9. 绘制了数据的相关系数热力图：
   
   - 创建了一个大小为 10x10 的画布。
   - 使用 `matshow()` 函数绘制了相关系数矩阵的热力图，并设置了颜色条。
   - 设置了刻度和标签，并调整了标签的角度以便显示。

#### 3.2回归拟合模型

这段代码是一个机器学习模型评估的示例，它使用了一系列回归算法对数据进行建模，并通过十折交叉验证来评估它们的性能。以下是代码的解读：

1. 导入了必要的库：
   
   - `numpy` 和 `pandas`：用于数据处理和数组操作。
   - `matplotlib.pyplot`：用于绘制图表。
   - `sklearn` 库中的相关模块：用于机器学习模型和评估。
   - `seaborn`：用于绘制图表美化。
   - `warnings`：用于忽略警告信息。

2. 设置中文字体为微软雅黑，并忽略警告信息。

3. 使用 `pd.read_csv()` 读取名为 "apple_quality.csv" 的数据文件，存储到名为 `data` 的 DataFrame 中，并打印出数据集的列名和形状。

4. 将数据转换为 DataFrame 格式。

5. 将数据分割为训练集、验证集和测试集。

6. 定义了回归算法模型：
   
   - 线性回归 (`LinearRegression`)
   - Lasso 回归 (`Lasso`)
   - 弹性网络回归 (`ElasticNet`)
   - K 最近邻回归 (`KNeighborsRegressor`)
   - 决策树回归 (`DecisionTreeRegressor`)
   - 支持向量回归 (`SVR`)

7. 使用十折交叉验证来评估每个模型的性能，并打印出每个模型的平均均方误差（neg_mean_squared_error）及其标准差。

8. 将每个模型的评估结果绘制成箱线图，用于比较不同算法的性能。

这段代码的目的是对比不同回归算法在数据集上的性能表现，以帮助选择最适合的模型。

#### 3.3分类算法

这段代码实现了几个分类器（K最近邻、支持向量机、随机森林）的建模和评估。我将逐步解读这段代码：

1. 导入了必要的库：
   
   - `numpy` 和 `pandas`：用于数据处理和数组操作。
   - `matplotlib.pyplot` 和 `seaborn`：用于绘图。
   - `sklearn` 库中的相关模块：用于机器学习模型和评估。
   - `warnings`：用于忽略警告信息。

2. 设置中文字体为微软雅黑，并忽略警告信息。

3. 使用 `pd.read_csv()` 读取名为 "apple_quality.csv" 的数据文件，存储到名为 `data` 的 DataFrame 中，并打印出数据集的列名和形状。

4. 将数据转换为 DataFrame 格式。

5. 将数据分割为训练集、验证集和测试集。

6. 定义了分类器的参数和模型对象：
   
   - K 最近邻分类器 (`KNeighborsClassifier`)
   - 支持向量机分类器 (`SVC`)
   - 随机森林分类器 (`RandomForestClassifier`)

7. 使用 K 最近邻分类器进行建模：
   
   - 对测试集进行预测，并计算得到真正率（True Positive Rate）和假正率（False Positive Rate）以绘制 ROC 曲线。
   - 进行参数优化，使用随机搜索（`RandomizedSearchCV`）寻找最佳参数组合。

8. 对支持向量机分类器和随机森林分类器执行了相似的操作。

9. 对每个分类器绘制了 ROC 曲线，输出了混淆矩阵热力图以及评估结果（准确率、精确率、召回率、F1 分数）。

10. 最后，使用验证集评估了模型的效果，并输出了评估结果。

这段代码的主要目的是比较不同分类器在数据集上的性能表现，并通过参数优化来提高模型性能。

#### 3.4 聚类分析

这段代码实现了对苹果质量数据集中的三个特征（大小、重量、甜度）进行 K-means 聚类，并可视化聚类结果。下面是代码的解读：

1. 导入了必要的库：
   
   - `pandas` 和 `numpy`：用于数据处理和数组操作。
   - `matplotlib.pyplot` 和 `mpl_toolkits.mplot3d.Axes3D`：用于绘制 3D 图表。
   - `sklearn.datasets.make_blobs` 和 `sklearn.cluster.KMeans`：用于生成数据和进行 K-means 聚类。
   - `matplotlib.font_manager`：用于设置字体。
   - `seaborn`：用于绘图美化。
   - `warnings`：用于忽略警告信息。

2. 设置中文字体为微软雅黑，并忽略警告信息。

3. 使用 `pd.read_csv()` 读取名为 "apple_quality.csv" 的数据文件，存储到名为 `data` 的 DataFrame 中，并提取出数据集的列名。

4. 提取出数据集中的特征矩阵 `X`，这里选择了前三列作为特征。

5. 定义了一个函数 `cluster()` 来执行聚类操作，其中：
   
   - 使用 `KMeans` 算法对数据进行聚类，设置聚类数为 3。
   - 对每个样本进行聚类预测，得到预测标签 `predict_y`。
   - 根据预测标签给每个样本设置颜色，并绘制 3D 散点图。
   - 给每个聚类中心添加标签。
   - 显示 3D 图表。

6. 在 `__name__ == '__main__'` 的条件下调用 `cluster()` 函数，执行聚类并展示结果。

这段代码的目的是对苹果质量数据集中的特征进行 K-means 聚类，并通过 3D 散点图展示聚类结果，以便观察不同特征在三维空间中的分布情况。

### 4、总结

非常简易初级的机器学习项目，使用了一些分类算法和参数优化算法，对与简单的二分类问题有较为不错的效果，呃...编不出来了😚


